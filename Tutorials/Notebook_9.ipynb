{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5851cc06",
   "metadata": {},
   "source": [
    "### Understanding Convolutional Neural Networks (CNNs)\n",
    "In this notebook we will work with the convolution technique applied to 2D images.\n",
    "Let us start by importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8839a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264e18cd",
   "metadata": {},
   "source": [
    "CNNs are a class of neural networks used for tasks involving images, such as classification, detection, and segmentation.\n",
    "They work by detecting patterns in images using filters (kernels) in a process called convolution.\n",
    "Convolution is an operation that slides a small matrix (called a kernel or filter) over an image and computes element-wise multiplications.\n",
    "This allows CNNs to detect edges, textures, and patterns.\n",
    "A 2D image is given by a 2D array, each element representing the intensity of the pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af8aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a simple convolution operation\n",
    "image = np.array([[2, 2, 2, 2, 2],\n",
    "                  [2, 4, 4, 4, 2],\n",
    "                  [2, 4, 8, 4, 2],\n",
    "                  [2, 4, 4, 4, 2],\n",
    "                  [2, 2, 2, 2, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0758aa2",
   "metadata": {},
   "source": [
    "Let us now visualize the image represented by this array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dabf18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(image):\n",
    "    \n",
    "    .........................\n",
    "\n",
    "visualize_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e63702",
   "metadata": {},
   "source": [
    "We can now define an array that will represent a filter or a kernel that acts on the image. Let us assume that the filter has 3x3 size (it can be smaller or bigger)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8e3a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[1, 0, -1],\n",
    "                   [1, 0, -1],\n",
    "                   [1, 0, -1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5caa67",
   "metadata": {},
   "source": [
    "And we can visualize the kernel as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee7f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_kernel(kernel):\n",
    "    \n",
    "   .........................\n",
    "\n",
    "visualize_kernel(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aef1bd6",
   "metadata": {},
   "source": [
    "A convolution is the element-wise multiplication of the kernel and subarrays of the image and the result is an array with the same shape as the filter. Afterwards, the elements of this result are summed to produce a scalar.\n",
    "When performing a convolution, two important parameters are the padding and the stride.\n",
    "Padding refers to the practice of adding extra rows and columns around an image to control how the convolutional filter interacts with its edges. In our case, we will use the function np.pad to apply padding to the image:\n",
    "image_padded = np.pad(image, pad_width=padding, mode='constant', constant_values=0)\n",
    "pad_width=padding indicates the number of pixels to add around the edges of the image. For example:\n",
    "- padding=1: Adds 1 row/column on all sides.\n",
    "- padding=2: Adds 2 rows/columns on all sides.\n",
    "Adding padding ensures preservation of spatial dimensions. Indeed, by padding the image, the output size can remain the same as the input size. It also ensures full coverage of edge pixels, since padding allows the kernel to process the edges of the image effectively.\n",
    "Stride refers to the step size or the number of pixels the convolutional filter (kernel) moves during each step as it slides across the image. It controls how much the filter shifts when it is applied to the input image. Stride=1 ensures maximum overlap between neighbouring regions, but increases the size of the output, whereas Stride>1 reduces the overlap while decreasing the size of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795b185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Convolution Manually\n",
    "\n",
    "def convolution2d(image, kernel, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    Perform 2D convolution between an image and a kernel.\n",
    "    \"\"\"\n",
    "    # Apply padding\n",
    "    image_padded = np.pad(image, pad_width=padding, mode='constant', constant_values=0)\n",
    "    \n",
    "    # Compute the output dimensions\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "    output_height = ((image_padded.shape[0] - kernel_height) // stride) + 1\n",
    "    output_width = ((image_padded.shape[1] - kernel_width) // stride) + 1\n",
    "    \n",
    "    # Initialize the output feature map\n",
    "    output = np.zeros((output_height, output_width))\n",
    "    \n",
    "    # Perform convolution\n",
    "    .........................\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa9e68",
   "metadata": {},
   "source": [
    "Now we can apply convolution of the example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply convolution on the example image\n",
    "output_feature_map = ........................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c558e9fe",
   "metadata": {},
   "source": [
    "And visualize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af8a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "........................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b91b82c",
   "metadata": {},
   "source": [
    "A commonly used technique in CNN is MaxPooling. It is a downsampling operation that reduces the spatial dimensions (height and width) of feature maps while retaining the most important information. The key idea is to condense information by selecting the maximum value from a small region (usually a square) of the feature map. Here, again, the two important parameters are the size of the region where the maximum will be computed and the stride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33451c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling(image, size=2, stride=2):\n",
    "    \"\"\"\n",
    "    Perform max pooling on an image with a given pool size and stride.\n",
    "    \"\"\"\n",
    "    output_height = (image.shape[0] - size) // stride + 1\n",
    "    output_width = (image.shape[1] - size) // stride + 1\n",
    "    pooled = np.zeros((output_height, output_width))\n",
    "    \n",
    "    .........................\n",
    "    \n",
    "    return pooled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17ee29f",
   "metadata": {},
   "source": [
    "Now we can apply MaxPooling to the feature map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7acf895",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_feature_map = ........................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446309df",
   "metadata": {},
   "source": [
    "And plot the result, which in this case is trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2cd1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "........................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f2e21f",
   "metadata": {},
   "source": [
    "After doing all the previous steps, we have all the elements to perform a CNN pipeline, by combining convolution and MaxPooling. We will also add an intermediate step consisting of a ReLU activation function. The basic pipeline includes: Convolution -> Activation (ReLU, using np.maximum) -> MaxPooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfdbc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convolution\n",
    "feature_map = .........................\n",
    "\n",
    "# Step 2: Activation Function (ReLU)\n",
    "feature_map_relu = .........................\n",
    "\n",
    "# Step 3: Max Pooling\n",
    "pooled_output = ........................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d673e3",
   "metadata": {},
   "source": [
    "And we can visualize all the steps of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e939e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "........................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d3db1a",
   "metadata": {},
   "source": [
    "Apply the pipeline to a bigger synthetic image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple synthetic image\n",
    "synthetic_image = np.array(.........................)\n",
    "\n",
    "# Kernel for edge detection\n",
    "edge_kernel = np.array([[1, 0, -1],\n",
    "                        [1, 0, -1],\n",
    "                        [1, 0, -1]])\n",
    "\n",
    "# Apply convolution\n",
    "synthetic_feature_map = .........................\n",
    "synthetic_feature_map_relu = .........................\n",
    "synthetic_pooled_output = .........................\n",
    "\n",
    "# Visualize Results\n",
    "........................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47163261",
   "metadata": {},
   "source": [
    "We will now apply the pipeline to a realistic image. For this, first load the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2371309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path, size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Load an image, resize it, and convert to grayscale.\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "    image = image.resize(size)\n",
    "    image_np = np.array(image)\n",
    "    return image_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98f7f06",
   "metadata": {},
   "source": [
    "And visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa9d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, title=\"Image\"):\n",
    "    \"\"\"\n",
    "    Display a grayscale image.\n",
    "    \"\"\"\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb31d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"cat.4150.jpg\"\n",
    "image = load_image(image_path)\n",
    "show_image(image, title=\"Original Grayscale Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7375d7b7",
   "metadata": {},
   "source": [
    "We will use three different kernels to study their impact on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feb7a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example kernels (filters)\n",
    "kernel_1 = np.array([[1, 0, -1],\n",
    "                    [1, 0, -1],\n",
    "                    [1, 0, -1]])\n",
    "\n",
    "kernel_2 = np.array([[0, -1, 0],\n",
    "                    [-1, 5, -1],\n",
    "                    [0, -1, 0]])\n",
    "\n",
    "kernel_3 = np.array([[1, 1, 1],\n",
    "                    [1, 1, 1],\n",
    "                    [1, 1, 1]]) / 9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e76ed7",
   "metadata": {},
   "source": [
    "Apply each of these kernels to the image and see what they do on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b6eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convolution with kernel 1 (do the same for the other kernels)\n",
    "feature_map_1 = .........................\n",
    "\n",
    "# Step 2: Apply ReLU activation\n",
    "relu_feature_map_1 = .........................\n",
    "\n",
    "# Step 3: Max Pooling\n",
    "pooled_relu_feature_map_1 = .........................\n",
    "\n",
    "# Visualize the CNN-like behavior\n",
    "........................."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
