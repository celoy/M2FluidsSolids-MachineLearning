{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28e1cdda",
   "metadata": {},
   "source": [
    "# Implementation of Principal Component Analysis (PCA) for image compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac82d7f7",
   "metadata": {},
   "source": [
    "This assignment aims to evaluate your understanding and application of Principal Component Analysis (PCA) for dimensionality reduction in the context of 2D image datasets. You will analyze, implement and interpret the results of PCA on a provided image dataset.\n",
    "For this purpose, use the data in the path=\"./cats/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702999ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725ca78f",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Complete the cell below to transform the images into greyscale, resize them so that they all have the same number of pixels and copy the values of the pixels into a 3D numpy array of shape (num_samples, height, width). Visualize a few sample images using imshow. Afterwards, flatten each image into a 1D array. This way, the initial 3D array becomes a 2D array of shape (num_samples, height*width)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8e24dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your answer in this cell\n",
    "\n",
    "# Path to the folder containing images\n",
    "path = ...........................  # Replace with the image folder path\n",
    "\n",
    "# Define the target size for resizing (height, width)\n",
    "target_size = (64, 64)  # You can adapt this as you want\n",
    "\n",
    "# Initialize an empty list to store grayscale images\n",
    "images = []\n",
    "\n",
    "# Loop through the files in the folder\n",
    "for filename in os.listdir(path):\n",
    "    image_path = os.path.join(path, filename)\n",
    "       \n",
    "    # Open the image and convert it to grayscale\n",
    "    image = Image.open(image_path).convert('L')\n",
    "\n",
    "    # Resize the image to the target size\n",
    "    image_resized = image.resize(.................)\n",
    "\n",
    "    # Convert the resized image to a numpy array and append to the images list\n",
    "    ........................\n",
    "\n",
    "# Convert the list of images to a 3D numpy array\n",
    "images_array = np.stack(images)\n",
    "\n",
    "# Visualize example images\n",
    "..........................\n",
    "\n",
    "# Flatten the images for PCA\n",
    "images_array_reshaped = ................................\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a802ac87",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Subtract the mean from each feature, i.e. along axis=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8003792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type here your answer\n",
    "X_mean = ..............................\n",
    "X_centered = ................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79779960",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Compute the covariance matrix of the centered data. What is the shape of the covariance matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490a9845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type here your answer\n",
    "................................"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc39eb",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Perform an SVD on the covariance matrix using numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f167ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type here your answer\n",
    "U, S, Vt = np.............................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bebd2f",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Project the data onto the principal components (select for the moment the number of components you want). Use for this the np.dot operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51303fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your answer here\n",
    "..............................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ada5df",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "Complete the cell below to keep the first $n$ components (select the number you want) and reconstruct some images using those first $n$ components. Check that when increasing $n$ the original image is recovered. Use any single image of the dataset, no need to do this for several images. Comment on this result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb6be21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type here your answer\n",
    "# Choose the number of principal components (n)\n",
    "n_list = .............\n",
    "X_approximation_list = []\n",
    "for i, n in enumerate(n_list):\n",
    "    principal_components = ............ # They are contained in the U matrix\n",
    "    X_pca = ............... # Use for this X_centered and principal_components\n",
    "    # Reconstruct the data\n",
    "    X_reconstructed = ................ # Use for this X_pca and the transpose of principal_components\n",
    "    # Append to the X_approximation list, but before that remember that\n",
    "    # the images that you are using for SVD have been modified in question 2\n",
    "    ......................................\n",
    "\n",
    "# Visualize example images\n",
    "................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403d1af3",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "The explained variance for each component is proportional to the square of the singular values, which are the elements of the diagonal of the matrix $S$. The explained variance ratio for the $i$-th component is\n",
    "$$\n",
    "r_i = \\frac{\\sigma_i^2}{\\sum_j\\sigma_j^2}\n",
    "$$\n",
    "where $\\sigma_i$ is the $i$-th singular value.\n",
    "Compute the diagonal matrix $R$, whose elements are $r_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f091e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your answer here\n",
    "....................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8baabc",
   "metadata": {},
   "source": [
    "# Question 8\n",
    "But what is important is the cumulative variance, which represents how much information of the image can be represented using the components up to a given order $n$.\n",
    "Calculate the cumulative sum of the explained variance ratio to see how much variance is captured as you add more components and plot the cumulative variance versus $n$. What is the behaviour that you observe? How many components do you need to keep to explain 95% of the variance? And 99%? How much do we compress the data if we explain 95% of the variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4096e4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your answer here\n",
    "......................................"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
